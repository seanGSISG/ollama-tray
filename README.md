# ğŸ¦™ Ollama Tray App

![Build & Release](https://github.com/seanGSISG/ollama-tray/actions/workflows/build-appimage.yml/badge.svg)

A lightweight Linux system tray application to monitor and control the `ollama` model server.

![image](https://github.com/user-attachments/assets/d545c412-3378-44a8-98e0-6c9a3594b744)


## âœ… Features

- Start/stop the `ollama` systemd service
- Monitor loaded models
- View GPU memory usage (NVIDIA only)
- See token context window usage
- Tray notifications for model events
- Open model directory in file manager
- **NEW:** Model management (pull/delete models)
- **NEW:** Run models directly in terminal from the UI
- **NEW:** Customizable settings via configuration UI
- **NEW:** About dialog with version information

## ğŸ§ª Requirements

- Linux (tested on Arch/KDE Wayland)
- Python 3.11+
- Python packages in `requirements.txt`

## ğŸš€ Quick Start

```bash
pip install -r requirements.txt
python3 app/ollama-tray.py
```

## ğŸ“ Project Structure

```
ollama-tray/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py        # Configuration management
â”‚   â”œâ”€â”€ models.py        # Model management utilities
â”‚   â”œâ”€â”€ ollama-tray.py   # Main application
â”‚   â”œâ”€â”€ ollama.png       # Application icon
â”‚   â”œâ”€â”€ ui.py            # UI components for settings and dialogs
â”‚   â””â”€â”€ version.py       # Version information
â”œâ”€â”€ appimage/
â”‚   â””â”€â”€ AppRun           # AppImage runner script
â”œâ”€â”€ .github/workflows/build-appimage.yml
â”œâ”€â”€ ollama-tray.desktop  # Desktop entry file
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Documentation
```

## âš™ï¸ Configuration

The application can be configured via the Settings dialog. Configuration is stored in `~/.config/ollama-tray/config.json`.

Available settings:

- **Service Name**: The systemd service name for ollama (default: `ollama.service`)
- **API URL**: The URL of the Ollama API (default: `http://127.0.0.1:11434`)
- **Model Directory**: The directory where models are stored (default: `~/.ollama/models`)
- **Refresh Interval**: How often the status is updated (default: `15000 ms`)
- **Log File**: The file where logs are written (default: `~/.cache/ollama-tray.log`)
- **Log Level**: The level of logging detail (default: `INFO`)

## ğŸ¤– Model Management

The Model Management feature allows you to:

1. **View Installed Models**: See all models currently installed in your Ollama instance
2. **Pull New Models**: Download new models from the Ollama library
3. **Remove Models**: Delete models you no longer need to free up disk space
4. **Monitor Disk Usage**: See how much disk space your models are using

Access model management through the tray menu option "Manage Models..."

### Available Models

Ollama supports various models including:

- `llama2` - Meta's Llama 2 models
- `mistral` - Mistral AI's models
- `gemma` - Google's Gemma models
- `phi` - Microsoft's Phi models
- `orca-mini` - Smaller, faster models
- And many more!

You can specify model variants like `llama2:7b` or `llama2:13b` when pulling.

## ğŸ“ License

MIT
